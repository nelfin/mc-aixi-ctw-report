\documentclass[pdftex,twoside,a4paper]{report}
\usepackage[pdftex]{graphicx}
\usepackage[margin=3.0cm]{geometry}
\usepackage[english]{babel}
\usepackage[normalem]{ulem}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{pgfplots}
\usepackage[sc]{mathpazo}
\usepackage[round]{natbib}

\newcommand{\hs}{$\hspace{0.5cm}$}
\newcommand{\bt}{\begin{tabbing}}
\newcommand{\et}{\end{tabbing}}
\newcommand{\bcen}{\begin{center}}
\newcommand{\ecen}{\end{center}}
\newcommand{\mac}{MC-AIXI-CTW}

\begin{document}

\begin{titlepage}
\renewcommand*{\thefootnote}{\fnsymbol{footnote}}
\begin{center}

\textsc{\Large Research School of Computer Science}\\[0.5cm]
\textsc{\Large College of Engineering and}\\[0.2cm]
\textsc{\Large Computer Science}\\[0.5cm]
\vspace{1.4cm}
\hrule
\vspace{1.4cm}
{\huge \bfseries An Implementation of MC-AIXI-CTW} \\
\vspace{0.4cm}


\begin{tabular}{ccccc}
  Jarrah Bloomfield\footnotemark &
  Luke English\footnotemark &
  Andrew Haigh\footnotemark &
  Joshua Nelson\footnotemark &
  Anthony Voutas\footnotemark
\end{tabular}

\vspace{1.4cm}
\hrule
\vspace{1.0cm}
\textsc{\large COMP4620 - Advanced Artificial Intelligence}\\
\textsc{Assignment 2}\\
\vspace{1.0cm}
\hrule
\vspace{1.4cm}
\vfill
%Bottom of the page
{\large \today} \\[0.5cm]

\begin{tabular}{ccccc}
  \setcounter{footnote}{0}
  u4669875\footnotemark &
  u4667010\footnotemark &
  u4667844\footnotemark &
  u4850020\footnotemark &
  u4519169\footnotemark
\end{tabular}
\end{center}
 
\end{titlepage}
\chapter{Description of the MC-AIXI-CTW implementation}

The AIXI agent is a formal, mathematical agent which represents a solution to
the general reinforcement learning problem. Principally, AIXI consists of an
expectimax search over a Bayesian mixture of Turing machines in order to
choose optimal actions by predicting future observations and rewards based on
past experience. Given infinite computational resources, AIXI represents the
optimal reinforcement agent: maximising future expected reward in any unknown
environment.

In the far more limited world of what is tractable, we require an
approximation to AIXI. Here, we approximate AIXI via a combination of UCT
search (Monte-Carlo Tree Search with the Upper Confidence Bound)
\citep{kocsis2006bandit} and Context Tree Weighting
\citep{willems1995context}, yielding MC-AIXI-CTW.

\chapter{User Manual}
\section{Arguments}
The agent can be compile with the \texttt{make} command. The agent then can then be run using\\

\texttt{./main <environment> <logfile>}\\

\texttt{<environment>} is a compulsory argument, which specifies the environment configuration file the agent is to use. In this implementation, it is one of the following
\begin{itemize}
\item \texttt{coinflip.conf}: Biased coin flip enviroment
\item \texttt{grid.conf}: Gridworld environment
\item \texttt{kuhnpoker.conf}: Kuhn poker environment
\item \texttt{pacman.conf}: Pacman environment
\item \texttt{rps.conf}: Biased rock paper scissors environment
\item \texttt{tiger.conf}: ``Tiger'' Environment
\item \texttt{composite.conf}: A combination of the above environments
\end{itemize}
\texttt{<logfile>} is an optional argument, which specifies the name of a log file to output results to.
\newline
\section{Configuration files}
\texttt{.conf} files are \emph{configuration files}, specifying which environment is to be used, and relevant parameters for each environment. Each configuration file has the following parameters
\begin{itemize}
\item \texttt{environment}: The name of the environment to use. One of \{4x4-grid, kuhn-poker, tiger, biased-rock-paper-scissor, pacman, composite\}.
\item \texttt{exploration}: The rate at which the agent explores, by making random decisions.
\item \texttt{explore-decay }: The rate at the exploration rate decreases
\end{itemize}
In addition to this, some configurations have parameters that are specific to their environments.
\begin{itemize}
\item Coinflip
    \begin{itemize}
        \item \texttt{coin-flip-p}: The probability of a flipping heads (0 $\leq$ \texttt{coin-flip-p}  $\leq$ 1).
    \end{itemize}
\item Kuhn poker
    \begin{itemize}
        \item \texttt{gamma}: A constant that determines the environment's Nash equilibrium strategy. (0 $\leq$ \texttt{gamma}  $\leq$ 1)
    \end{itemize}
\item Pacman
    \begin{itemize}
        \item \texttt{mapfile}: The location of the map file for the pacman board.
    \end{itemize}
\item tiger.conf
    \begin{itemize}
        \item \texttt{left-door-p}: The probability that the gold is behind the left door
        \item \texttt{listen-p}: The probability that a listening observation is correct.
    \end{itemize}
\item composite.conf
    \begin{itemize}
        \item \texttt{environmentN}: Specifies the $N^{\text{th}}$ environment, where $0 \leq N \leq 10$. The value of this parameter is an integer $\leq 10$, and indicates which environment environmentN represents.
        \item \texttt{startN}: Specifies the time step that at which the $N^{\text{th}}$ environment starts, where $0 \leq N \leq 10$.
        \item Paremeters required for the environemnts $1..N$ specified in \texttt{environment.cpp}.
    \end{itemize}
\end{itemize}

\chapter{MC-AIXI-CTW Implementation}
\section{Design Choices}

We have implemented MC-AIXI-CTW in the C++ coding language, which has a number of benefits and drawbacks. 

\section{Context Tree Weighting}
The algorithm for implementing context-tree weighting (CTW) mainly consists of the methods and objects given in the file \texttt{predict.cpp}, along with its corresponding \texttt{.hpp} file. We run through these from the beginning of the file to its end.  

\subsection{Objects}
\begin{itemize}
\item{\texttt{CTNode}

This object represents a node in the context tree; and so it needs to store both the Laplacian estimate of the probability, along with the weight given to it by the actual CTW algorithm. For mathematical stability, we store these floating-point numbers as logarithms, so we can just add them instead of multiplying them. In addition, it has a 2-array of pointers to its left and right child, and it stores the counts for these nodes in the context of the history (which is also required for the CTW algorithm).
  }
\item{\texttt{ContextTree}

Here we have the entire context tree represented as an object, which is a glorified pointer to the root node of the tree (as \texttt{CTNode}s store their own children). In addition to storing the root, \texttt{ContextTree} also stores a double-ended queue of symbols (boolean integers) which represents the current history of the tree, and an unsigned integer which represents the maximum depth of the tree (so that we don't add nodes past the depth, and take up more memory than we want).
  }
\end{itemize}

\subsection{Methods}
\subsubsection{\texttt{CTNode}}
\begin{itemize}
\item{\texttt{logProbWeighted, logProbEstimated, visits, child}}

    These methods are simply defined. Since the values stored in variables such as \texttt{m\_log\_prob\_weighted} are declared privately, it is required to use a public method to get them. \texttt{visits} grabs the sum of the counts for the child nodes - the number of times that we have seen this particular node in our travels; and \texttt{child} takes a symbol, and returns a pointer to the correct (left or right) child.
}
\item{\texttt{update}

    \texttt{update} is one of the most important methods in the entire CTW implementation. We recurse through the tree, starting from the node that calls this method, popping symbols from the end of the history until we reach a leaf; as in the CTW algorithm. When we do, we update the counts for the leaf based on the symbol that is passed to \texttt{update}, and then follow the branch back up the tree, using the equation given for $P_{w}$: \[ P_{w} = \frac{1}{2}P_{KT}(n) + \frac{1}{2}P^{0}P^{1}. \] % can someone check this against the literature?
This method doesn't change the history, as we push the popped symbols back onto the stack when we're done with each call.
  }
\item{\texttt{size}
    
    This is a simple method; it counts the total size of the subtree with the calling node as the root. 
  }
\item{\texttt{logKTMul}
    
    This method calculates the Laplacian estimator $P_{KT}$ for the node, given a symbol $n \in \{0,1\}$, where \[ P_{KT}(n) = \frac{\#n + 0.5}{\#n + \#(1-n) + 1}.\] This forms the base multiplier for the probabilities in the context tree.
  }
\item{\texttt{revert}
    
    If \texttt{update} is the method which adds a symbol to the context tree, then \texttt{revert} is the method which removes it. We again recurse down the tree, removing the symbol from the leaf, and pushing the changes back up the tree using the current history. Again, we don't change the history with this method.
  }
\item{\texttt{prettyPrintNode}
    
    Mainly used for testing, this method prints the counts and probabilities at a node, indented given the depth in the tree.
  }
\end{itemize}
\subsubsection{\texttt{ContextTree}}
\begin{itemize}
\item{\texttt{clear}
    
    Instead of using the generic destructor \texttt{~ContextTree}, this method simply deletes the existing history and disassociates the pointer to the root, making a new root and associating the tree with that root instead.
  }
\item{\texttt{update}

    This is an overloaded method, which can either take in a symbol, or a list of symbols. If passed a list, it simply runs itself on each of the symbols in turn; and if passed a symbol, it first checks whether we have enough pre-history to generate a tree. If we don't, it simply pushes the symbol to the back of the history (where we can easily access it again), and if we do, then we need to actually change nodes; so we call the \texttt{update} method from \texttt{CTNode} instead, before pushing the symbol onto the history.
  }
\item{\texttt{updateHistory}
    
    Here we simply push a list of symbols onto the back of the history.
  }
\item{\texttt{revert}
    
    This version of \texttt{revert} pops the last symbol off the history, and uses it to pass to the \texttt{CTNode} version. It is useful because only the \texttt{ContextTree} has access to the variable \texttt{m\_history}.
  }
\item{\texttt{revertHistory}
    
    Unlike \texttt{revert}, this method takes in a size to revert back to (this corresponds to a previous age of the context tree), and simply pops symbols from the history until we get back to that size. 
  }
\item{\texttt{genRandomSymbols}
    
    This method utilises the following \texttt{genRandomSymbolsAndUpdate} method to make a string of random symbols on the history, utilising \texttt{revert} in order to remove the changes that the following method makes to the tree.
  }
\item{\texttt{genRandomSymbolsAndUpdate}
    
    As the name implies, this method uses the context-tree weights to form a random distribution, upon which it generates \texttt{bits} bits and pushes them to the given symbol list, and then updates the context-tree weightings.
  }
\item{\texttt{logBlockProbability}
    
    This is a simple getter method for the weighted probability of the root - which is the probability of the entire context tree.
  }
\item{\texttt{nthHistorySymbol}
    
    Again, this method is aptly named: it returns the $n$th most recent history symbol. (Of course, when it can't find a symbol back that far, it just returns \texttt{NULL} instead.)
  }
\item{\texttt{depth, historySize, size}
    
    These are simple getter methods for the private variables contained within a \texttt{ContextTree}.
  }
\item{\texttt{predictNext}
    
    This method uses the weighted context-tree to make an educated guess about what the next symbol may be. It predicts the probability of a 1 being the next symbol, then uses a random generator to figure out whether it should guess 1 or 0.
  }
\item{\texttt{prettyPrint, printHistory}
    
    These methods are printing methods - \texttt{prettyPrint} uses the \texttt{prettyPrintNode} method from \texttt{CTNode} to recursively print the entire tree, indented by level; and \texttt{printHistory} just prints a single string of each symbol in the history, with spaces for separators.
  }
\end{itemize}
\section{Upper Confidence Tree}

\section{Revert Function}
\chapter{Experimentation}
\section{Sequence prediction}
\label{sec:Sequence prediction}
The CTW tree is the primarmy prediction mechanism in the \mac{} model. The CTW implementation of \mac{} was tested in isolation from the rest of the agent on a range of deterministic and non-deterministic sequence. This was useful for debugging purposes, and the results are an interesting biproduct of \mac{}.
\subsection{Deterministic sequence prediction}
Several simple sequences were given to the CTW tree, and the CTW tree was asked to continue the sequence. This can be seen in Figure \ref{tab:det_seq_pred}. We can see that the CTW tree is able to correctly predict the next bit, or multiple bits, in the sequence.

\begin{figure}
\bcen
\bgroup
\def\arraystretch{1.5}
\begin{tabular}{|cc|cc|}
\hline
Sequence & Prediction & Sequence & Prediction\\
\hline $0^{1000}$ & 0... & $1^{1000}$ & 1...\\ 
\hline $(01)^{1000}$ & 01... & $(10)^{1000}$ & 10...\\ 
\hline $(0110)^{500}$ & 0110... & $(1100)^{500}$ & 1100...\\ 
\hline $(110)^{500}$ & 110... & $(001)^{500}$ & 001...\\
\hline 
\end{tabular} 
\egroup
\ecen
\caption{Some of the sequences given to the CTW tree, and the prediction of the next symbol.}
\label{tab:det_seq_pred}
\end{figure}

\subsection{Non deterministic sequence prediction}
A partially non deterministic sequence was given to CTW for testing purposes. The sequence was given to CTW was of the form\\
\[
S := x^{\text{obs}}_0,\; x^{\text{rew}}_0,\; x^{\text{act}}_1,\; x^{\text{obs}}_1,\; x^{\text{rew}}_1, x^{\text{act}}_2,\; x^{\text{obs}}_2,\; x^{\text{rew}}_2, ...
\]
Where\\
\[
x^{\text{act}}_i := r_{\text{act}}, \;\;\;\; x^{\text{obs}}_i := r_{\text{obs}}, \;\;\;\; \text{and} \;\;\;\;
x^{\text{rew}}_i :=
\begin{cases}
0 & \text{if } x^{\text{obs}}_i = x^{\text{act}}_i\\
1 & \text{if } x^{\text{obs}}_i \not= x^{\text{act}}_i
\end{cases}
\]
Where\\
\[
r_\text{act}, r_\text{obs} \text{ are random bits }
\]

The idea of this sequence $S$ is to simulate a coinflip environment history sequence. The random bits $x^{\text{obs}}_i$ and $x^{\text{act}}_i$ simulate random coin flips, and the reward bit $x^{\text{act}}_i$ compares them. The action bit $x^{\text{act}}_i$ is random in this sequence.

A sequence of this type with size ~9000 (3000 iterations) is given to the CTW tree, up to the point
\[
S = x^{\text{obs}}_0,\; x^{\text{rew}}_0,\; x^{\text{act}}_1,\;\;\;...\;\;\;,x^{\text{act}}_{3000},\;x^{\text{obs}}_{3000}
\]

The CTW tree is then asked to predict which bit is the next in the sequence. The idea of this experiment is to determine if the CTW tree ``understands'' the rules of the game - if it understood, it would predict $x^{\text{rew}}_{3000} = (x^{\text{act}}_{3000} \land x^{\text{obs}}_{3000}) \lor (\lnot x^{\text{act}}_{3000} \land \lnot x^{\text{obs}}_{3000})$.

The results of this experiment are show in Figure \ref{tab:non_det_seq_pred}. We see that it correctly predicts the reward bit given the action and observation bits. This provides some verification that the implementation of the CTW tree is correct.
\begin{figure}
\bcen
\bgroup
\def\arraystretch{1.5}
\begin{tabular}{c |c| c }
 â€¢ & $x^{\text{rew}}_{3000} = 0$ & $x^{\text{rew}}_{3000} = 1$ \\ 
\hline $x^{\text{rew}}_{3000} = 0$ & 1 & 0 \\ 
\hline $x^{\text{rew}}_{3000} = 1$ & 0 & 1 \\  
\end{tabular}
\egroup
\ecen
\caption{Predicted values for $x^{\text{rew}}_{3000}$}
\label{tab:non_det_seq_pred}
\end{figure}

\section{Coin flip results}
Coin flip is a simple environment where the agent is given a reward of 1 for correctly guessing the next bit, where the next bit is random with a certain bias such that the next bit is 1 with probability $\theta \in [0,1]$, else the reward is 0. For a regular coin, $\theta = 0.5$, and there is no dominant strategy. However, if $\theta \not = 0.5$, dominant strategies emerge ($\theta > 0.5 \Rightarrow $ predict 1, $\; \theta < 0.5 \Rightarrow $ predict 0). The variable $\theta$ is hidden from the agent.




\section{Tiger results}
The parameters used were:\\\\
\begin{tabular}{| r | l | }
\hline
mc-simulations & 50\\
exploration & 0.01\\
explore-decay & 0.999\\
\hline
\end{tabular}
\section{Grid world results}

\begin{tabular}{| r | l | }
\hline
mc-simulations & 50\\
exploration & 0.01\\
explore-decay & 0.99999\\
\hline
\end{tabular}
\section{Biased Rock paper scissors results}
In Biased Rock Paper Scissors (RPS), the agent plays against an environment which will randomly select rock, paper or scissors; but after winning with rock, the environment will repeat a rock move. This is interesting because it creates a bias in the environment's distribution, and the agent needs to try to exploit this bias.\\\\
The parameters used were:\\\\
\begin{tabular}{| r | l | }
\hline
mc-simulations & 50\\
exploration & 0.1\\
explore-decay & 0.999\\
\hline
\end{tabular}
\section{Kuhn Poker results}
In Kuhn Poker, the agent plays against a Nash Equillibruim AI, with gamma set to 0.5. The agent is given a reward of 0 for a loss, 2 for a win or 1 if no showdown has occurred so far.\\\\
The parameters used were:\\\\
\begin{tabular}{| r | l | }
\hline
mc-simulations & 50\\
exploration & 0.01\\
explore-decay & 0.9999\\
\hline
\end{tabular}
\section{Pacman results}
In Pacman\\\\
The parameters used were:\\\\
\begin{tabular}{| r | l | }
\hline
mc-simulations & 50\\
exploration & 0.01\\
explore-decay & 0.99999\\
\hline
\end{tabular}

 \begin{center}
\emph{Table 5.1 Number of problems where complete solutions were found}
\end{center}
The parameters used were:
\chapter{Extension}
This is just a test figure, to see what happens with PGFPlots and such.
\begin{figure}[h]
\begin{center}
  \begin{tikzpicture}
    \begin{axis}[xlabel=Cycle,ylabel=Average reward,title={Coinflip $p=0.2$}]
      \pgfplotstableread{graph_data/coinflip_p=0_2.plot.csv}\plotcsv
      \addplot+[every mark/.append style={no markers},smooth] table
      {\plotcsv};
    \end{axis}
  \end{tikzpicture}
\end{center}
\end{figure}

\bibliographystyle{plainnat}
\bibliography{refs}

\end{document}
