\documentclass[pdftex,twoside,a4paper]{report}
\usepackage[pdftex]{graphicx}
\usepackage[margin=3.0cm]{geometry}
\usepackage[english]{babel}
\usepackage[normalem]{ulem}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[sc]{mathpazo}
\usepackage[round]{natbib}

\newcommand{\hs}{$\hspace{0.5cm}$}
\newcommand{\bt}{\begin{tabbing}}
\newcommand{\et}{\end{tabbing}}
\newcommand{\bcen}{\begin{center}}
\newcommand{\ecen}{\end{center}}
\newcommand{\mac}{MC-AIXI-CTW}

\begin{document}

\begin{titlepage}
\renewcommand*{\thefootnote}{\fnsymbol{footnote}}
\begin{center}

\textsc{\Large Research School of Computer Science}\\[0.5cm]
\textsc{\Large College of Engineering and}\\[0.2cm]
\textsc{\Large Computer Science}\\[0.5cm]
\vspace{1.4cm}
\hrule
\vspace{1.4cm}
{\huge \bfseries An Implementation of MC-AIXI-CTW} \\
\vspace{0.4cm}


\begin{tabular}{ccccc}
  Luke English\footnotemark &
  Andrew Haigh\footnotemark &
  Jarrah Bloomfield\footnotemark &
  Joshua Nelson\footnotemark &
  Anthony Voutas\footnotemark
\end{tabular}

\vspace{1.4cm}
\hrule
\vspace{1.0cm}
\textsc{\large COMP4620 - Advanced Artificial Intelligence}\\
\textsc{Assignment 2}\\
\vspace{1.0cm}
\hrule
vspace{1.4cm}
\vfill
Bottom of the page
{\large \today} \\[0.5cm]

\begin{tabular}{ccccc}
  \setcounter{footnote}{0}
  u4669875\footnotemark &
  u4667010\footnotemark &
  u4669875\footnotemark &
  u4850020\footnotemark &
  u4519169\footnotemark
\end{tabular}
\end{center}
 
\end{titlepage}
\chapter{Description of the MC-AIXI-CTW implementation}

The AIXI agent is a formal, mathematical agent which represents a solution to
the general reinforcement learning problem. Principally, AIXI consists of an
expectimax search over a Bayesian mixture of Turing machines in order to
choose optimal actions by predicting future observations and rewards based on
past experience. Given infinite computational resources, AIXI represents the
optimal reinforcement agent: maximising future expected reward in any unknown
environment.

In the far more limited world of what is tractable, we require an
approximation to AIXI. Here, we approximate AIXI via a combination of UCT
search (Monte-Carlo Tree Search with the Upper Confidence Bound)
\citep{kocsis2006bandit} and Context Tree Weighting
\citep{willems1995context}, yielding MC-AIXI-CTW.

\chapter{User Manual}
\section{Arguments}
The agent can be compile with the \texttt{make} command. The agent then can then be run using\\

\texttt{./main <environment> <logfile>}\\

\texttt{<environment>} is a compulsory argument, which specifies the environment configuration file the agent is to use. In this implementation, it is one of the following
\begin{itemize}
\item \texttt{coinflip.conf}: Biased coin flip enviroment
\item \texttt{grid.conf}: Gridworld environment
\item \texttt{kuhnpoker.conf}: Kuhn poker environment
\item \texttt{pacman.conf}: Pacman environment
\item \texttt{rps.conf}: Biased rock paper scissors environment
\item \texttt{tiger.conf}: ``Tiger'' Environment
\item \texttt{composite.conf}: A combination of the above environments
\end{itemize}
\texttt{<logfile>} is an optional argument, which specifies the name of a log file to output results to.
\newline
\section{Configuration files}
\texttt{.conf} files are \emph{configuration files}, specifying which environment is to be used, and relevant parameters for each environment. Each configuration file has the following parameters
\begin{itemize}
\item \texttt{environment}: The name of the environment to use. One of \{4x4-grid, kuhn-poker, tiger, biased-rock-paper-scissor, pacman, composite\}.
\item \texttt{exploration}: The rate at which the agent explores, by making random decisions.
\item \texttt{explore-decay }: The rate at the exploration rate decreases
\end{itemize}
In addition to this, some configurations have parameters that are specific to their environments.
\begin{itemize}
\item Coinflip
    \begin{itemize}
        \item \texttt{coin-flip-p}: The probability of a flipping heads (0 $\leq$ \texttt{coin-flip-p}  $\leq$ 1).
    \end{itemize}
\item Kuhn poker
    \begin{itemize}
        \item \texttt{gamma}: A constant that determines the environment's Nash equilibrium strategy. (0 $\leq$ \texttt{gamma}  $\leq$ 1)
    \end{itemize}
\item Pacman
    \begin{itemize}
        \item \texttt{mapfile}: The location of the map file for the pacman board.
    \end{itemize}
\item tiger.conf
    \begin{itemize}
        \item \texttt{left-door-p}: The probability that the gold is behind the left door
        \item \texttt{listen-p}: The probability that a listening observation is correct.
    \end{itemize}
\item composite.conf
    \begin{itemize}
        \item \texttt{environmentN}: Specifies the $N^{\text{th}}$ environment, where $0 \leq N \leq 10$. The value of this parameter is an integer $\leq 10$, and indicates which environment environmentN represents.
        \item \texttt{startN}: Specifies the time step that at which the $N^{\text{th}}$ environment starts, where $0 \leq N \leq 10$.
        \item Paremeters required for the environemnts $1..N$ specified in \texttt{environment.cpp}.
    \end{itemize}
\end{itemize}

\chapter{MC-AIXI-CTW Implementation}
\section{Context Tree Weighting}

\section{Upper Confidence Tree}

\section{Revert Function}

\chapter{Experimentation}
\label{sec:Experimentation}

\section{Learning}
\label{sec:Learning}
\subsection{Sequence prediction}
The CTW tree is the primarmy prediction mechanism in the \mac{} model. The CTW implementation of \mac{} was tested in isolation from the rest of the agent on a range of deterministic and non-deterministic sequence.

\section{Extension}
\label{sec:Extension}

\bibliographystyle{plainnat}
\bibliography{refs}

\end{document}